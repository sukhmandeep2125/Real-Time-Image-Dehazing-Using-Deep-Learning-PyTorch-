# -*- coding: utf-8 -*-
"""_second.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h2XEbzz4GNdqURNA6U686Uubrald-X8U
"""

import os
import glob
import random
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from tqdm import tqdm
from skimage.metrics import peak_signal_noise_ratio as compare_psnr

class DehazingDataset(Dataset):
    def __init__(self, pairs):
        self.pairs = pairs
        self.transform = transforms.Compose([
            transforms.Resize((256, 256)),  # Fixed size
            transforms.ToTensor()
        ])

    def __len__(self):
        return len(self.pairs)

    def __getitem__(self, idx):
        hazy_path, clean_path = self.pairs[idx]
        hazy = Image.open(hazy_path).convert("RGB")
        clean = Image.open(clean_path).convert("RGB")
        return self.transform(hazy), self.transform(clean)

class DeepDehazeNet(nn.Module):
    def __init__(self):
        super().__init__()

        def conv_block(in_c, out_c):
            return nn.Sequential(
                nn.Conv2d(in_c, out_c, 3, padding=1),
                nn.BatchNorm2d(out_c),
                nn.ReLU(inplace=True),
                nn.Dropout(0.2)
            )

        # Encoder
        self.enc1 = conv_block(3, 64)
        self.pool1 = nn.MaxPool2d(2)
        self.enc2 = conv_block(64, 128)
        self.pool2 = nn.MaxPool2d(2)
        self.enc3 = conv_block(128, 256)
        self.pool3 = nn.MaxPool2d(2)

        # Bottleneck
        self.bottleneck = conv_block(256, 512)
        self.pool4 = nn.MaxPool2d(2)

        # Decoder
        self.up1 = nn.ConvTranspose2d(512, 256, 2, stride=2)
        self.dec1 = conv_block(512, 256)
        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)
        self.dec2 = conv_block(256, 128)
        self.up3 = nn.ConvTranspose2d(128, 64, 2, stride=2)
        self.dec3 = conv_block(128, 64)

        self.final = nn.Conv2d(64, 3, 1)

    def forward(self, x):
        # Encoder
        e1 = self.enc1(x)          # [B,64,256,256]
        e2 = self.enc2(self.pool1(e1))  # [B,128,128,128]
        e3 = self.enc3(self.pool2(e2))  # [B,256,64,64]
        b = self.bottleneck(self.pool3(e3))  # [B,512,32,32]

        # Decoder
        d1 = self.dec1(torch.cat([self.up1(b), e3], 1))  # [B,256,64,64]
        d2 = self.dec2(torch.cat([self.up2(d1), e2], 1))  # [B,128,128,128]
        d3 = self.dec3(torch.cat([self.up3(d2), e1], 1))  # [B,64,256,256]
        return torch.sigmoid(self.final(d3))  # [B,3,256,256]

import os
cwd = os.getcwd()
hazy_dir = os.path.join(cwd,"hazy")
clean_dir = os.path.join(cwd,"clear")

print("Hazy exists:", os.path.exists(hazy_dir))
print("Clean exists:", os.path.exists(clean_dir))

import os, glob

print("Hazy images found:", len(glob.glob(os.path.join(hazy_dir, '*'))))
print("Clean images found:", len(glob.glob(os.path.join(clean_dir, '*'))))

pairs = list(zip(hazy_paths, clean_paths))

hazy_paths = sorted(glob.glob(os.path.join(hazy_dir, '*')))
clean_paths = sorted(glob.glob(os.path.join(clean_dir, '*')))
pairs = list(zip(hazy_paths, clean_paths))

# Shuffle & split
random.shuffle(pairs)
total = len(pairs)
train_pairs = pairs[:int(0.8*total)]
val_pairs = pairs[int(0.8*total):int(0.9*total)]
test_pairs = pairs[int(0.9*total):]

# Create datasets
train_dataset = DehazingDataset(train_pairs)
val_dataset = DehazingDataset(val_pairs)
test_dataset = DehazingDataset(test_pairs)

train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = DeepDehazeNet().to(device)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)

num_epochs = 300
best_psnr = 0
loss_history = []
psnr_history = []

for epoch in range(num_epochs):
    # Training
    model.train()
    epoch_loss = 0
    for hazy, clean in tqdm(train_loader):
        hazy, clean = hazy.to(device), clean.to(device)

        optimizer.zero_grad()
        outputs = model(hazy)
        loss = criterion(outputs, clean)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)
        optimizer.step()
        epoch_loss += loss.item()

    # Validation
    model.eval()
    val_loss = 0
    total_psnr = 0
    with torch.no_grad():
        for hazy, clean in val_loader:
            hazy, clean = hazy.to(device), clean.to(device)
            outputs = model(hazy)
            val_loss += criterion(outputs, clean).item()

            # Calculate PSNR
            outputs_np = outputs.cpu().numpy()
            clean_np = clean.cpu().numpy()
            psnr = compare_psnr(clean_np, outputs_np, data_range=1.0)
            total_psnr += psnr

    # Update metrics
    avg_loss = epoch_loss/len(train_loader)
    avg_psnr = total_psnr/len(val_loader)
    loss_history.append(avg_loss)
    psnr_history.append(avg_psnr)

    print(f"Epoch {epoch+1}/{num_epochs}")
    print(f"Train Loss: {avg_loss:.4f} | Val PSNR: {avg_psnr:.2f} dB")

    # Save best model
    if avg_psnr > best_psnr:
        best_psnr = avg_psnr
        best1 = os.path.join(cwd,"best_dehaze1")
        torch.save(model.state_dict(), 'best1.pth')

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(loss_history, label='Loss')
plt.title("Training Loss")
plt.subplot(1,2,2)
plt.plot(psnr_history, color='orange', label='PSNR')
plt.title("Validation PSNR")
plt.show()

# Test & save results
model.load_state_dict(torch.load(os.path.join(cwd,"best1.pth")))
model.eval()
os.makedirs('IOP24/ sukhman/dehazed_results', exist_ok=True)

with torch.no_grad():
    for idx, (hazy, _) in enumerate(test_loader):
        output = model(hazy.to(device))
        output_img = output.squeeze().cpu().numpy().transpose(1,2,0)
        output_img = (output_img * 255).clip(0, 255).astype(np.uint8)
        cv2.imwrite(f'IOP24/ sukhman/dehazed_results/result_{idx}.jpg',
                   cv2.cvtColor(output_img, cv2.COLOR_RGB2BGR))

print("Dehazing complete! Results saved to Google Drive.")

